{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answer Extraction Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, argparse, gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, create_optimizer, DefaultDataCollator, AdamWeightDecay\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-multilingual-cased\"\n",
    "maxlen = 512\n",
    "stride = 128\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2068 entries, 0 to 2067\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   context       2068 non-null   object\n",
      " 1   question      2068 non-null   object\n",
      " 2   answer        2068 non-null   object\n",
      " 3   answer_start  2068 non-null   int64 \n",
      " 4   answer_end    2068 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 80.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"datasets/test.csv\")\n",
    "df_test.drop(\"title\", axis=1, inplace=True)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[\"context_len\"] = df_test[\"context\"].apply(lambda x: len(x.split()))\n",
    "df_test[\"context_len\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(ds, tokenizer, maxlen, stride):\n",
    "    questions = [q.strip() for q in ds[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        ds[\"context\"],\n",
    "        max_length=maxlen,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    # answers = ds[\"answer\"]\n",
    "    answer_starts = ds[\"answer_start\"]\n",
    "    answer_ends = ds[\"answer_end\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        # answer = answers[sample_idx]\n",
    "        start_char = answer_starts[sample_idx]\n",
    "        end_char = answer_ends[sample_idx]\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a82744577414185d5b1765edac520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2068, 3291)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = datasets.Dataset.from_dict(df_test)\n",
    "\n",
    "dataset_test = ds_test.map(\n",
    "    lambda ds: preprocess_dataset(ds, tokenizer, maxlen, stride),\n",
    "    batched=True,\n",
    "    remove_columns=ds_test.column_names,\n",
    ")\n",
    "len(ds_test), len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 3291\n",
       "})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0]['end_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "tf_dataset_test = dataset_test.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\",\n",
    "    ],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-09-04 13:56:02.395524: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open models/bert-base-multilingual-cased: FAILED_PRECONDITION: models/bert-base-multilingual-cased; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f551279cc70>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model(f\"models/{model_name}\", compile=False)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "model.load_weights(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  177262848 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,264,386\n",
      "Trainable params: 177,264,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_question_context(question, context, tokenizer, maxlen, stride):\n",
    "    question = question.strip()\n",
    "    context = context.strip()\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=maxlen,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        # return_overflowing_tokens=True,\n",
    "        # return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, context, tokenizer, maxlen, stride):\n",
    "    inputs = tokenize_question_context(question, context, tokenizer, maxlen, stride)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    start_logits = outputs[\"start_logits\"].numpy()\n",
    "    end_logits = outputs[\"end_logits\"].numpy()\n",
    "\n",
    "    starts = np.argmax(start_logits, axis=1)\n",
    "    ends = np.argmax(end_logits,  axis=1)\n",
    "\n",
    "    start_scores = np.max(start_logits, axis=1)\n",
    "    end_scores = np.max(end_logits, axis=1)\n",
    "    scores = start_scores + end_scores\n",
    "\n",
    "    indices = []\n",
    "    for idx, start in enumerate(starts):\n",
    "        end = ends[idx]\n",
    "        if start == 0 and end == 0:\n",
    "            continue\n",
    "        if end < start:\n",
    "            continue\n",
    "        indices.append(idx)\n",
    "\n",
    "    answers = []\n",
    "    for idx in indices:\n",
    "        score = scores[idx]\n",
    "        ans_ids = inputs[\"input_ids\"][idx][starts[idx]:ends[idx]+1]\n",
    "        answer = tokenizer.decode(ans_ids, skip_special_tokens=True)\n",
    "        answers.append((answer, score))\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Từ một cô gái năng động, hoạt bát, trầm cảm kh...</td>\n",
       "      <td>Từ một cô gái năng động, hoạt bát, bệnh gì khi...</td>\n",
       "      <td>trầm cảm</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Từ một cô gái năng động, hoạt bát, trầm cảm kh...</td>\n",
       "      <td>Cô có những biểu hiện như thế nào với tất cả n...</td>\n",
       "      <td>lầm lỳ, buồn chán và sợ hãi</td>\n",
       "      <td>115</td>\n",
       "      <td>142</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Từ một cô gái năng động, hoạt bát, trầm cảm kh...</td>\n",
       "      <td>Cô ấy nghĩ gì để giải thoát những nổi ám ảnh?</td>\n",
       "      <td>tự tử</td>\n",
       "      <td>321</td>\n",
       "      <td>326</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Từ một cô gái năng động, hoạt bát, trầm cảm kh...</td>\n",
       "      <td>Nghe theo lời khuyên của huấn luyện viên, Linh...</td>\n",
       "      <td>khóa tu Vipassana (thiền tịnh khẩu) trong một ...</td>\n",
       "      <td>948</td>\n",
       "      <td>1032</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Từ một cô gái năng động, hoạt bát, trầm cảm kh...</td>\n",
       "      <td>Mai Linh bây giờ đã biết những gì?</td>\n",
       "      <td>yêu thương bản thân, bớt sợ hãi và dễ dàng tìm...</td>\n",
       "      <td>3223</td>\n",
       "      <td>3321</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "30  Từ một cô gái năng động, hoạt bát, trầm cảm kh...   \n",
       "31  Từ một cô gái năng động, hoạt bát, trầm cảm kh...   \n",
       "32  Từ một cô gái năng động, hoạt bát, trầm cảm kh...   \n",
       "33  Từ một cô gái năng động, hoạt bát, trầm cảm kh...   \n",
       "34  Từ một cô gái năng động, hoạt bát, trầm cảm kh...   \n",
       "\n",
       "                                             question  \\\n",
       "30  Từ một cô gái năng động, hoạt bát, bệnh gì khi...   \n",
       "31  Cô có những biểu hiện như thế nào với tất cả n...   \n",
       "32      Cô ấy nghĩ gì để giải thoát những nổi ám ảnh?   \n",
       "33  Nghe theo lời khuyên của huấn luyện viên, Linh...   \n",
       "34                 Mai Linh bây giờ đã biết những gì?   \n",
       "\n",
       "                                               answer  answer_start  \\\n",
       "30                                           trầm cảm            35   \n",
       "31                        lầm lỳ, buồn chán và sợ hãi           115   \n",
       "32                                              tự tử           321   \n",
       "33  khóa tu Vipassana (thiền tịnh khẩu) trong một ...           948   \n",
       "34  yêu thương bản thân, bớt sợ hãi và dễ dàng tìm...          3223   \n",
       "\n",
       "    answer_end  context_len  \n",
       "30          43          727  \n",
       "31         142          727  \n",
       "32         326          727  \n",
       "33        1032          727  \n",
       "34        3321          727  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_test[df_test[\"context_len\"] > 500]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ông Bình phát hiện ung thư thanh quản cách đây...</td>\n",
       "      <td>Cách đây 3 năm ông Bình mắc bệnh gì?</td>\n",
       "      <td>ung thư thanh quản</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ông Bình phát hiện ung thư thanh quản cách đây...</td>\n",
       "      <td>Với kỹ thuật cũ, liệu trình trị xạ là bao nhiê...</td>\n",
       "      <td>30 lần</td>\n",
       "      <td>1263</td>\n",
       "      <td>1269</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ông Bình phát hiện ung thư thanh quản cách đây...</td>\n",
       "      <td>Phương pháp mới có ngưỡng sai số là bao nhiêu?</td>\n",
       "      <td>một mm</td>\n",
       "      <td>1451</td>\n",
       "      <td>1457</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ông Bình phát hiện ung thư thanh quản cách đây...</td>\n",
       "      <td>Kỹ thuật mới áp dụng cho những trường hợp nào?</td>\n",
       "      <td>bướu nhỏ, giai đoạn sớm, tái phát còn khu trú ...</td>\n",
       "      <td>1589</td>\n",
       "      <td>1722</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ông Bình phát hiện ung thư thanh quản cách đây...</td>\n",
       "      <td>Với kỹ thuật cũ, ngưỡng sai số của liều xạ là ...</td>\n",
       "      <td>lên đến 5-10 mm</td>\n",
       "      <td>1294</td>\n",
       "      <td>1309</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Ông Bình phát hiện ung thư thanh quản cách đây...   \n",
       "1  Ông Bình phát hiện ung thư thanh quản cách đây...   \n",
       "2  Ông Bình phát hiện ung thư thanh quản cách đây...   \n",
       "3  Ông Bình phát hiện ung thư thanh quản cách đây...   \n",
       "4  Ông Bình phát hiện ung thư thanh quản cách đây...   \n",
       "\n",
       "                                            question  \\\n",
       "0               Cách đây 3 năm ông Bình mắc bệnh gì?   \n",
       "1  Với kỹ thuật cũ, liệu trình trị xạ là bao nhiê...   \n",
       "2     Phương pháp mới có ngưỡng sai số là bao nhiêu?   \n",
       "3     Kỹ thuật mới áp dụng cho những trường hợp nào?   \n",
       "4  Với kỹ thuật cũ, ngưỡng sai số của liều xạ là ...   \n",
       "\n",
       "                                              answer  answer_start  \\\n",
       "0                                 ung thư thanh quản            19   \n",
       "1                                             30 lần          1263   \n",
       "2                                             một mm          1451   \n",
       "3  bướu nhỏ, giai đoạn sớm, tái phát còn khu trú ...          1589   \n",
       "4                                    lên đến 5-10 mm          1294   \n",
       "\n",
       "   answer_end  context_len  \n",
       "0          37          388  \n",
       "1        1269          388  \n",
       "2        1457          388  \n",
       "3        1722          388  \n",
       "4        1309          388  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('30 lần và ngưỡng sai số có thể lên đến 5 - 10 mm', 17.33732)]\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "# question = df.loc[idx, \"question\"]\n",
    "# context = df.loc[idx, \"context\"]\n",
    "question = df_test.loc[idx, \"question\"]\n",
    "context = df_test.loc[idx, \"context\"]\n",
    "\n",
    "answers = predict(model, question, context, tokenizer, maxlen, stride)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 3291)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = dataset_test['start_positions']\n",
    "end_positions = dataset_test['end_positions']\n",
    "\n",
    "len(start_positions), len(end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 2140s 10s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 3291)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = predictions.start_logits\n",
    "end_logits = predictions.end_logits\n",
    "\n",
    "pred_start_positions = np.argmax(start_logits, axis=1)\n",
    "pred_end_positions = np.argmax(end_logits, axis=1)\n",
    "\n",
    "len(pred_start_positions), len(pred_end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6274688544515344\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i, start in enumerate(start_positions):\n",
    "    end = end_positions[i]\n",
    "    pred_start = pred_start_positions[i]\n",
    "    pred_end = pred_end_positions[i]\n",
    "    if start == pred_start and end == pred_end:\n",
    "        acc += 1\n",
    "\n",
    "acc /= len(start_positions)\n",
    "print(\"Accuracy :\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc23d0c91bea4b07bad21e2ea8dc7c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2068, 3069)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = datasets.Dataset.from_dict(df_test)\n",
    "\n",
    "dataset_test = ds_test.map(\n",
    "    lambda ds: preprocess_dataset(ds, tokenizer, maxlen, stride),\n",
    "    batched=True,\n",
    "    remove_columns=ds_test.column_names,\n",
    ")\n",
    "len(ds_test), len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "tf_dataset_test = dataset_test.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\",\n",
    "    ],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d34b548cc44d789b3911a8ee3f8da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForQuestionAnswering.\n",
      "\n",
      "Some layers of TFXLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-09-04 16:54:04.791233: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open models/xlm-roberta-base: FAILED_PRECONDITION: models/xlm-roberta-base; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5437c1c940>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "model.load_weights(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3069, 3069)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = dataset_test['start_positions']\n",
    "end_positions = dataset_test['end_positions']\n",
    "\n",
    "len(start_positions), len(end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 2140s 11s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3069, 3069)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = predictions.start_logits\n",
    "end_logits = predictions.end_logits\n",
    "\n",
    "pred_start_positions = np.argmax(start_logits, axis=1)\n",
    "pred_end_positions = np.argmax(end_logits, axis=1)\n",
    "\n",
    "len(pred_start_positions), len(pred_end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6480938416422287\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i, start in enumerate(start_positions):\n",
    "    end = end_positions[i]\n",
    "    pred_start = pred_start_positions[i]\n",
    "    pred_end = pred_end_positions[i]\n",
    "    if start == pred_start and end == pred_end:\n",
    "        acc += 1\n",
    "\n",
    "acc /= len(start_positions)\n",
    "print(\"Accuracy :\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c2d2a96cd34051ba6cbef7a070b0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b21dd4bee04f80b805fafd61e392a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4abedf44cc8495abee05e12a88cd0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dffb58085e4f00b2129b77daacabfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2068, 3069)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = datasets.Dataset.from_dict(df_test)\n",
    "\n",
    "dataset_test = ds_test.map(\n",
    "    lambda ds: preprocess_dataset(ds, tokenizer, maxlen, stride),\n",
    "    batched=True,\n",
    "    remove_columns=ds_test.column_names,\n",
    ")\n",
    "len(ds_test), len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "tf_dataset_test = dataset_test.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\",\n",
    "    ],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad1494abc6543e0a0540e7d2dd9785e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForQuestionAnswering.\n",
      "\n",
      "Some layers of TFXLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-09-05 12:14:13.828560: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open models/xlm-roberta-large: FAILED_PRECONDITION: models/xlm-roberta-large; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6b48372b20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "model.load_weights(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3069, 3069)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = dataset_test['start_positions']\n",
    "end_positions = dataset_test['end_positions']\n",
    "\n",
    "len(start_positions), len(end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 7266s 38s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3069, 3069)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = predictions.start_logits\n",
    "end_logits = predictions.end_logits\n",
    "\n",
    "pred_start_positions = np.argmax(start_logits, axis=1)\n",
    "pred_end_positions = np.argmax(end_logits, axis=1)\n",
    "\n",
    "len(pred_start_positions), len(pred_end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6966438579341805\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i, start in enumerate(start_positions):\n",
    "    end = end_positions[i]\n",
    "    pred_start = pred_start_positions[i]\n",
    "    pred_end = pred_end_positions[i]\n",
    "    if start == pred_start and end == pred_end:\n",
    "        acc += 1\n",
    "\n",
    "acc /= len(start_positions)\n",
    "print(\"Accuracy :\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05ba19d9ae51d22527c9d8a581a8f071558a6865eb84731cb7012e43c774991b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
